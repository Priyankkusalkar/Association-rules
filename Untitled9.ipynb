{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7620e4cd-2965-4ad4-b5de-6e675497cbc3",
   "metadata": {},
   "source": [
    "#### Assignment_No_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a283a121-264e-426d-aa20-2182d0ee7abf",
   "metadata": {},
   "source": [
    "#### ASSOCIATION RULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc8fbe22-94b2-4a14-8adc-fc95fdad33c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>burgers,meatballs,eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chutney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>turkey,avocado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mineral water,milk,energy bar,whole wheat rice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low fat yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>butter,light mayo,fresh bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>burgers,frozen vegetables,eggs,french fries,ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>escalope,green tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>eggs,frozen smoothie,yogurt cake,low fat yogurt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil\n",
       "0                                burgers,meatballs,eggs                                                                                                                                                                             \n",
       "1                                               chutney                                                                                                                                                                             \n",
       "2                                        turkey,avocado                                                                                                                                                                             \n",
       "3     mineral water,milk,energy bar,whole wheat rice...                                                                                                                                                                             \n",
       "4                                        low fat yogurt                                                                                                                                                                             \n",
       "...                                                 ...                                                                                                                                                                             \n",
       "7495                      butter,light mayo,fresh bread                                                                                                                                                                             \n",
       "7496  burgers,frozen vegetables,eggs,french fries,ma...                                                                                                                                                                             \n",
       "7497                                            chicken                                                                                                                                                                             \n",
       "7498                                 escalope,green tea                                                                                                                                                                             \n",
       "7499    eggs,frozen smoothie,yogurt cake,low fat yogurt                                                                                                                                                                             \n",
       "\n",
       "[7500 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(r\"C:\\Users\\Laptop\\Downloads\\data science Assignments\\Association Rules\\Association Rules\\Online retail.xlsx\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae77a65b-0de4-4a0c-8800-686afb719ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Dataset:\n",
    "####Use the Online retail dataset to apply the association rules.\n",
    "####Data Preprocessing:\n",
    "####Pre-process the dataset to ensure it is suitable for Association rules, this may include handling missing values, removing duplicates, and converting the data to appropriate format.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef905a8-8035-4745-b058-f855c5b5af07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil    0\n",
      "dtype: int64\n",
      "Duplicate Rows: 2325\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(r\"C:\\Users\\Laptop\\Downloads\\data science Assignments\\Association Rules\\Association Rules\\Online retail.xlsx\")\n",
    "\n",
    "# Step 1: Handling Missing Values\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Depending on the missing value distribution and attributes affected, handle missing values accordingly\n",
    "# For example, drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Step 2: Removing Duplicates\n",
    "# Check for duplicates\n",
    "duplicate_rows = data.duplicated().sum()\n",
    "print(\"Duplicate Rows:\", duplicate_rows)\n",
    "\n",
    "# Remove duplicate rows\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Step 3: Converting Data to Appropriate Format\n",
    "# Group the data by InvoiceNo (or the correct column name) and create lists of items purchased in each transaction\n",
    "# Replace 'InvoiceNo' with the correct transaction ID column name\n",
    "#if 'InvoiceNo' in data.columns:\n",
    "    #transactions = data.groupby('InvoiceNo')['Description'].apply(list).reset_index(name='Items')\n",
    "#else:\n",
    "    # If 'InvoiceNo' is not found, prompt the user to input the correct column name\n",
    "    #transaction_id_column = input(\"Please enter the correct column name for transaction IDs: \")\n",
    "    #transactions = data.groupby(transaction_id_column)['Description'].apply(list).reset_index(name='Items')\n",
    "\n",
    "# Print first few transactions to verify\n",
    "#print(\"First Few Transactions:\")\n",
    "#print(transactions.head())\n",
    "\n",
    "# Now, the 'transactions' DataFrame contains transactional data suitable for association rule analysis\n",
    "\n",
    "# Further preprocessing steps such as encoding categorical variables or handling sparse data\n",
    "# may also be necessary depending on the specific requirements of the association rule analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "216cd7e9-a543-40a6-a1f1-24558db78f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtendNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading mlxtend-0.23.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from mlxtend) (1.11.4)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from mlxtend) (2.2.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from mlxtend) (1.2.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from mlxtend) (3.8.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from mlxtend) (1.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\laptop\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.1-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.4 MB 262.6 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.1/1.4 MB 409.6 kB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.1/1.4 MB 328.6 kB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.1/1.4 MB 327.7 kB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.1/1.4 MB 327.7 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.1/1.4 MB 328.4 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.1/1.4 MB 328.4 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.1/1.4 MB 315.4 kB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.2/1.4 MB 296.2 kB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.2/1.4 MB 296.2 kB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.2/1.4 MB 296.2 kB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.2/1.4 MB 276.3 kB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 0.2/1.4 MB 265.4 kB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 0.2/1.4 MB 265.4 kB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 0.2/1.4 MB 265.1 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.2/1.4 MB 269.8 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.2/1.4 MB 262.3 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.2/1.4 MB 262.3 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 0.3/1.4 MB 257.9 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 0.3/1.4 MB 252.2 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 0.3/1.4 MB 252.2 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 0.3/1.4 MB 253.0 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.3/1.4 MB 260.5 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.3/1.4 MB 255.4 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.3/1.4 MB 255.4 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 0.3/1.4 MB 255.8 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 0.3/1.4 MB 254.5 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 0.4/1.4 MB 254.9 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 0.4/1.4 MB 254.9 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 0.4/1.4 MB 260.8 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 0.4/1.4 MB 254.2 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 0.4/1.4 MB 259.6 kB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 0.4/1.4 MB 259.6 kB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 0.4/1.4 MB 253.5 kB/s eta 0:00:05\n",
      "   ------------ --------------------------- 0.5/1.4 MB 258.6 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 0.5/1.4 MB 258.7 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 0.5/1.4 MB 258.7 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 0.5/1.4 MB 255.6 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 0.5/1.4 MB 257.9 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 0.5/1.4 MB 255.0 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 0.5/1.4 MB 259.2 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 0.6/1.4 MB 261.2 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 0.6/1.4 MB 262.2 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 0.6/1.4 MB 262.2 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 0.6/1.4 MB 262.2 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 0.6/1.4 MB 259.4 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 0.6/1.4 MB 264.9 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 0.6/1.4 MB 266.6 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 0.6/1.4 MB 263.9 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 0.7/1.4 MB 267.2 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 0.7/1.4 MB 266.2 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 0.7/1.4 MB 269.4 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 0.7/1.4 MB 272.5 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.7/1.4 MB 273.1 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.7/1.4 MB 274.4 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.8/1.4 MB 273.4 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.8/1.4 MB 273.4 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 0.8/1.4 MB 271.6 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 0.8/1.4 MB 271.6 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 0.8/1.4 MB 271.9 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 0.8/1.4 MB 271.9 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 0.8/1.4 MB 271.7 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 0.8/1.4 MB 270.9 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 0.9/1.4 MB 272.0 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 0.9/1.4 MB 272.0 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 0.9/1.4 MB 271.7 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 0.9/1.4 MB 271.0 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 0.9/1.4 MB 272.1 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 0.9/1.4 MB 271.3 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 0.9/1.4 MB 271.3 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 0.9/1.4 MB 271.1 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 0.9/1.4 MB 271.1 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.0/1.4 MB 268.5 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.0/1.4 MB 268.5 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.0/1.4 MB 263.3 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.0/1.4 MB 263.3 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.0/1.4 MB 263.3 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.0/1.4 MB 263.3 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.0/1.4 MB 260.6 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.0/1.4 MB 260.6 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.0/1.4 MB 260.6 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.0/1.4 MB 260.6 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.1/1.4 MB 259.1 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.1/1.4 MB 259.1 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.1/1.4 MB 258.2 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.1/1.4 MB 258.2 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.1/1.4 MB 255.8 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.1/1.4 MB 255.8 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.1/1.4 MB 255.0 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.1/1.4 MB 255.1 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.1/1.4 MB 255.1 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.1/1.4 MB 253.0 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.2/1.4 MB 254.0 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.2/1.4 MB 254.0 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 1.2/1.4 MB 251.9 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 1.2/1.4 MB 251.9 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 1.2/1.4 MB 252.1 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 1.2/1.4 MB 253.1 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.2/1.4 MB 251.1 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.2/1.4 MB 251.1 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.2/1.4 MB 252.1 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.2/1.4 MB 250.2 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.4 MB 252.7 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.4 MB 252.7 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.4 MB 251.3 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.4 MB 251.3 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.4 MB 249.5 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.3/1.4 MB 250.4 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.3/1.4 MB 250.4 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.3/1.4 MB 249.4 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.4 MB 251.1 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.4 MB 251.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.4/1.4 MB 250.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.4/1.4 MB 250.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.4/1.4 MB 251.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.4/1.4 MB 250.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.4/1.4 MB 252.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 252.4 kB/s eta 0:00:00\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.1\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d5c41-a810-41cd-8e14-05a6eb250e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Association Rule Mining:\n",
    "####â€¢\tImplement an Apriori algorithm using tool like python with libraries such as Pandas and Mlxtend etc.\n",
    "####â€¢\t Apply association rule mining techniques to the pre-processed dataset to discover interesting relationships between products purchased together.\n",
    "####â€¢\tSet appropriate threshold for support, confidence and lift to extract meaning full rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02b74a58-e181-49ba-8826-7f33dabaf9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading dataset: 'unicodeescape' codec can't decode bytes in position 16637-16638: truncated \\uXXXX escape\n",
      "Error preprocessing data: name 'data' is not defined\n",
      "Error grouping data: name 'data' is not defined\n",
      "Error encoding data: name 'basket' is not defined\n",
      "Error applying Apriori algorithm: name 'basket' is not defined\n",
      "Error generating association rules: name 'frequent_itemsets' is not defined\n",
      "Error filtering rules: name 'rules' is not defined\n",
      "Error displaying filtered rules: name 'filtered_rules' is not defined\n",
      "Error saving rules to CSV: name 'filtered_rules' is not defined\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    data = pd.read_csv(r\"C:\\Users\\Laptop\\Downloads\\data science Assignments\\Association Rules\\Association Rules\\Online retail.xlsx\", encoding='unicode_escape')\n",
    "    print(\"Dataset loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Data Preprocessing\n",
    "try:\n",
    "    # Drop rows with missing values\n",
    "    data.dropna(inplace=True)\n",
    "    # Remove duplicates\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    print(\"Data preprocessed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error preprocessing data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Group by InvoiceNo and Description to create a basket\n",
    "try:\n",
    "    basket = data.groupby(['InvoiceNo', 'Description'])['Quantity'].sum().unstack().reset_index().fillna(0).set_index('InvoiceNo')\n",
    "    print(\"Data grouped successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error grouping data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Convert the basket into 1-hot encoded format\n",
    "def encode_units(x):\n",
    "    return 1 if x > 0 else 0\n",
    "\n",
    "try:\n",
    "    basket = basket.applymap(encode_units)\n",
    "    print(\"Data encoded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error encoding data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Apply the Apriori algorithm\n",
    "try:\n",
    "    frequent_itemsets = apriori(basket, min_support=0.01, use_colnames=True)\n",
    "    print(\"Apriori algorithm applied successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error applying Apriori algorithm: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Generate the association rules\n",
    "try:\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "    print(\"Association rules generated successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error generating association rules: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Set thresholds for support, confidence, and lift\n",
    "try:\n",
    "    filtered_rules = rules[(rules['support'] >= 0.01) &\n",
    "                           (rules['confidence'] >= 0.5) &\n",
    "                           (rules['lift'] >= 1)]\n",
    "    print(\"Rules filtered successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error filtering rules: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Display the filtered rules\n",
    "try:\n",
    "    print(filtered_rules.head())\n",
    "    print(\"Filtered rules displayed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error displaying filtered rules: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Optional: Save the rules to a CSV file\n",
    "try:\n",
    "    filtered_rules.to_csv('association_rules.csv', index=False)\n",
    "    print(\"Rules saved to CSV successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving rules to CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bfa1fe-100f-4b70-9ad6-7b65ef009b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Analysis and Interpretation:\n",
    "####â€¢\tAnalyse the generated rules to identify interesting patterns and relationships between the products.\n",
    "####â€¢\tInterpret the results and provide insights into customer purchasing behaviour based on the discovered rules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858bb8e4-74f6-490b-a682-92783d44c0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully\n",
      "Data preprocessed successfully\n",
      "Error grouping data: 'InvoiceNo'\n",
      "Error encoding data: name 'basket' is not defined\n",
      "Error generating frequent itemsets: name 'basket_sets' is not defined\n",
      "Error generating association rules: name 'frequent_itemsets' is not defined\n",
      "Error displaying top rules: name 'rules' is not defined\n",
      "\n",
      "Analysis and Interpretation:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'top_rules' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Analyze and Interpret the results\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnalysis and Interpretation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, rule \u001b[38;5;129;01min\u001b[39;00m top_rules\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     69\u001b[0m     antecedent \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(rule[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mantecedents\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     70\u001b[0m     consequent \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(rule[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconsequents\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top_rules' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    data = pd.read_excel(r\"C:\\Users\\Laptop\\Downloads\\data science Assignments\\Association Rules\\Association Rules\\Online retail.xlsx\")\n",
    "    print(\"Dataset loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Data Preprocessing\n",
    "try:\n",
    "    # Drop rows with missing values\n",
    "    data.dropna(inplace=True)\n",
    "    # Remove duplicates\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    print(\"Data preprocessed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error preprocessing data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Group by InvoiceNo and Description to create a basket\n",
    "try:\n",
    "    basket = data.groupby(['InvoiceNo', 'Description'])['Quantity'].sum().unstack().reset_index().fillna(0).set_index('InvoiceNo')\n",
    "    print(\"Data grouped successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error grouping data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Convert the basket into 1-hot encoded format\n",
    "def encode_units(x):\n",
    "    return 1 if x > 0 else 0\n",
    "\n",
    "try:\n",
    "    basket_sets = basket.applymap(encode_units)\n",
    "    print(\"Data encoded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error encoding data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Apply Apriori algorithm to generate frequent itemsets\n",
    "try:\n",
    "    frequent_itemsets = apriori(basket_sets, min_support=0.01, use_colnames=True)\n",
    "    print(\"Frequent itemsets generated successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error generating frequent itemsets: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Generate association rules\n",
    "try:\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "    print(\"Association rules generated successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error generating association rules: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Display the top 10 association rules based on lift\n",
    "try:\n",
    "    top_rules = rules.sort_values(by='lift', ascending=False).head(10)\n",
    "    print(\"Top 10 Association Rules based on Lift:\")\n",
    "    print(top_rules)\n",
    "except Exception as e:\n",
    "    print(f\"Error displaying top rules: {e}\")\n",
    "\n",
    "# Analyze and Interpret the results\n",
    "print(\"\\nAnalysis and Interpretation:\")\n",
    "for index, rule in top_rules.iterrows():\n",
    "    antecedent = ', '.join(rule['antecedents'])\n",
    "    consequent = ', '.join(rule['consequents'])\n",
    "    support = rule['support']\n",
    "    confidence = rule['confidence']\n",
    "    lift = rule['lift']\n",
    "    \n",
    "    print(f\"Rule: {antecedent} => {consequent}\")\n",
    "    print(f\"Support: {support:.4f}, Confidence: {confidence:.4f}, Lift: {lift:.4f}\")\n",
    "    \n",
    "    # Interpretation and Insights\n",
    "    print(\"Interpretation and Insights:\")\n",
    "    # Add your interpretations based on the antecedent and consequent items\n",
    "    # Example interpretations:\n",
    "    if 'milk' in antecedent:\n",
    "        print(\"Customers who buy milk are likely to buy\", consequent)\n",
    "    elif 'chocolate' in antecedent:\n",
    "        print(\"Customers who buy chocolate are likely to buy\", consequent)\n",
    "    # Add more interpretations based on different antecedents or consequents\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7151708a-1c2e-4918-9403-88f5d1da6145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
